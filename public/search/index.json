[{"content":"Hugo博客教程（一） 博客 静态博客 静态博客是指利用生成工具（如：Hugo、Hexo）等将博文编译成静态文件的一种博客系统。博主只需要将生成文件部署在静态服务器上即可被互联网访问，在访问时，直接获取静态资源，不需要向数据库中请求博文、图片等信息。\n静态博客的优缺点 优点\n速度快：用户在访问博客时，只需要获取静态资源，不需要向服务器查询博文、图片等信息。\n部署方便、成本低：市面上有许多免费开源的托管程序，不需要承担高昂的服务器费用。\n维护方便：服务器维护成本低。\n迁移方便：无数据库系统，迁移时，不需要专门进行数据库迁移操作，只需保存原始博文即可。\n安全：无需担心数据库注入、跨站攻击等网络安全问题。\n缺点\n不支持原生注册登录、原生评论，需要使用第三方评论工具。第三方评论工具的安全性和速度质疑。\n入门难度大，不易上手。静态博客的内容管理和操作都有一定的难度，需要一定的编程基础。\n常见的静态博客 Hexo 基于Node.js的静态网站生成器，近几年（截止到2023年）的发展不如以前那么好，主题多，教程多，官方文档丰富，可以很快的搭建出漂亮的博客页面。由于其基于Node.js的特点，当博客数量增多时，渲染时间长。\n所以Hexo适用于博客数量少，更新周期长的博主。\nHugo Hugo是一个基于Go语言开发的静态网站生成器，Hugo的突出特点是简洁、灵活、高效。近几年（截止到2023年）发展迅速，越来越多的网站开始使用Hugo搭建。相比于Hexo，其渲染速度快，配置简单。但是其主题相比于Hexo较少。\nHugo适合于博客数量多，更新周期短的博主。\n动态博客 动态博客是指当服务器收到访问请求时，会结合数据库，调用相应的程序，动态生成需要传回的页面文件。动态博客相比于静态博客最大的区别在于其需要数据库的参与。\n动态博客的优缺点 优点\n网页动态生成，对于不同用户，不同时间的访问展现不同的页面内容。\n功能强大：动态博客相比于静态博客的功能更加强大。比如对数据库的支持、注册登录、访问量统计、原生评论的支持。\n交互性强：因为其支持原生评论和访问量统计的特点，相比于静态博客具有更好的交互性。\n缺点\n浪费系统资源：因为其与数据库交互的，所以相比于静态博客更消耗系统资源，浏览速度慢。\n易遭受攻击：因为动态博客需要支持数据库，还有后端代码，所以更易受到数据库注入和跨站攻击等威胁。\n维护迁移困难：相比于静态博客只需要保存静态资源，动态博客的迁移不仅需要重新部署博客，还需要迁移数据库，修改配置等操作，在迁移中容易出现操作失误导致迁移失败重新迁移。\n成本高：需要独立的服务器部署博客网站。\n常见的动态博客 WordPress 全球最著名的博客网站，并逐步演化为内容管理系统软件。拥有世界上最强大的插件和模板。功能强大、扩展性强。缺点是插件和模板对于国内的支持不好，国内访问速度缓慢。\nTypecho 国内开源的一个动态博客平台，相比于WordPress更加轻巧、快速。原生默认采用MarkDown编辑器，相比于WordPress的编辑器更加高效。\n为什么选择静态博客 静态博客和动态博客相比各有优劣，但是相比较而言，搭建个人博客，最方便、成本最低、体验最好的就是静态博客。相比于动态博客需要的服务器部署，目前有很多平台支持免费的静态博客部署，成本更低，有需要的只需要买一个域名即可支持每年搭建个人博客所需要的金钱耗费。随着个人博客的发展，静态博客也是目前的趋势所在。\n当然动态博客也有自己的优势，动态博客的功能性、互操性更强，而且动态博客需要部署在服务器上，有自己的一台服务器可以干很多事情，不仅是搭建个人博客，甚至可以搭建自己的云盘、图库、邮件系统、甚至是通过服务器来学习相关的Linux操作系统知识。\n在众多静态博客中，Hugo不是最流行的，但却是未来的静态博客的趋势所在。相比于Hexo的需要安装Node.js，Hugo基于Go打包的二进制文件，只需要把文件下载下来并添加到环境变量中即可使用，且Hugo的渲染速度相比于Hexo更快，更适合有长期写博客人的需求。\nHugo的安装与配置 Hugo中文文档 (gohugo.org)\nHugo官方官网(gohugo.io)\nHugo安装包下载地址：Releases · gohugoio/hugo (github.com)\n在下载Hugo安装包时，有Hugo和Hugo-extended两种可运行文件下载，其中Hugo仅支持JS，Hugo-extended是Hugo的扩展版本，在支持JS的基础上还支持TS，所以在下载时建议下载Hugo-extended版本的可执行文件。\nWindows系统的安装与配置 在Hugo安装包下载地址：Releases · gohugoio/hugo (github.com)下载好Hugo.exe文件后，将Hugo.exe文件放在想要存放的位置即可，比如我这里放在D:\\Blog\\Hugo文件夹下面，此时在该文件夹下面打开cmd命令提示符即可运行Hugo的相关命令，运行命令Hugo命令实际上就是在调用Hugo.exe文件。\nWindows环境变量配置 此电脑 \u0026ndash; 属性 \u0026ndash; 高级系统设置 \u0026ndash; 高级 \u0026ndash;环境变量 \u0026ndash; Path\n在Windows的系统环境变量配置中，添加存放Hugo.exe文件的文件夹，确定之后即可在其他任意地方运行Hugo命令而不是仅在安装位置运行。\nLinux系统的安装与配置 Hugo在Linux上的安装与配置和Windows类似。首先wget下载指定的Hugo压缩文件（tar.gz文件一般是Linux系统的压缩文件），以v0.110.0版本为例：\n1 2 3 4 # 下载指定版本的Hugo文件 wget https://github.com/gohugoio/hugo/releases/download/v0.110.0/hugo_extended_0.110.0_linux-amd64.tar.gz # 解压tar.gz压缩文件 tar -zxvf hugo_extended_0.110.0_linux-amd64.tar.gz 解压后，使用mv命令将可执行文件移动到想要存放的路径。\nLinux环境变量配置 Linux修改本用户的环境变量一般需要修改用户目录下的bashrc文件即~/.bashrc文件，在文件中加入export PATH=$PATH:{PATH}即可，修改后的文件不会立即生效，需要使用source ~/.bashrc命令重新加载bashrc文件即可完成环境变量配置。\n1 2 3 4 5 6 7 8 # 打开~/.bashrc文件 vim ~/.bashrc # 在bashrc文件中加入环境变量配置 # 在修改bashrc文件时注意添加注释，避免之后找不到相关配置 # /home/user/blog/Hugo是我存放Hugo文件的目录，在配置时根据自己的情况按需修改 export PATH=$PATH:/home/user/blog/Hugo # 保存修改，退出后在shell界面重新加载bashrc文件 source ~/.bashrc 安装检查 在配置好环境变量后，在cmd或者shell（尽量不要在可执行文件存放的位置中）中运行Hugo命令检查是否安装成功，一般而言使用version查看是否安装成功。\n在cmd和shell中执行：\n1 hugo version 成功示例：\n1 hugo v0.110.0-e32a493b7826d02763c3b79623952e625402b168+extended windows/amd64 BuildDate=2023-01-17T12:16:09Z VendorInfo=gohugoio ","date":"2023-02-01T00:00:00Z","permalink":"/post/blog/hugo/hugo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%B8%80/","title":"Hugo博客教程（一）"},{"content":"一：实验内容 掌握python进行图像处理、了解opencv-python库的使用 基于robert、prewitt、sobel算子完成图像边缘提取 了解SUSAN、Harris、SIFT算子的特征检测 二：实验过程 （一）边缘提取 （1）卷积算子 a：robert交叉算子 b：prewitt算子 c：sobel算子 d：laplacian算子 （2）实验代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import cv2 import numpy as np def _edge_extraction(img: np.ndarray, kernel_method=\u0026#39;robert\u0026#39;): \u0026#34;\u0026#34;\u0026#34; 边缘提取 :param img: 需要进行边缘提取的图，COLOR：BGR :param kernel_method: 边缘提取算子名称，全小写 :return: x方向（0.5x）和y方向（0.5y）边缘提取的加权和 \u0026#34;\u0026#34;\u0026#34; # 转换为灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 边缘提取算子 if \u0026#39;robert\u0026#39; == kernel_method: kernel_x = np.array([[-1, 0], [0, 1]], dtype=int) kernel_y = np.array([[0, -1], [1, 0]], dtype=int) elif \u0026#39;prewitt\u0026#39; == kernel_method: kernel_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=int) kernel_y = np.array([[1, 1, 1], [0, 0, 0], [1, 1, 1]], dtype=int) elif \u0026#39;sobel\u0026#39; == kernel_method: kernel_x = np.array([[-1, 0, 1], [-2, 0, -2], [-1, 0, 1]], dtype=int) kernel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=int) elif \u0026#39;laplacian\u0026#39; == kernel_method: kernel_x = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=int) kernel_y = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=int) else: kernel_x = np.array([[-1, 0], [0, 1]], dtype=int) kernel_y = np.array([[0, -1], [1, 0]], dtype=int) # 进行边缘提取 filter_x = cv2.filter2D(gray, ddepth=-1, kernel=kernel_x) filter_y = cv2.filter2D(gray, ddepth=-1, kernel=kernel_y) # x方向和y方向加权 img_add_weight = cv2.addWeighted(filter_x, 0.5, filter_y, 0.5, 0) return img_add_weight def image_show(img: np.ndarray, title=\u0026#39;img\u0026#39;): \u0026#34;\u0026#34;\u0026#34; 显示图片 :param img: :param title: :return: \u0026#34;\u0026#34;\u0026#34; cv2.namedWindow(title) cv2.imshow(title, img) cv2.waitKey(0) def edge_extraction(path: str, kernel_method=\u0026#39;robert\u0026#39;): # 读取图片 img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR) # 边缘提取 img_extraction = _edge_extraction(img, kernel_method=kernel_method) # 显示图片 image_show(img_extraction, kernel_method) （二）特征点检测 （1）实验代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 import cv2 import numpy as np def feature_point_detection_susan(img: np.ndarray): \u0026#34;\u0026#34;\u0026#34; susan特征点检测 :param img: :return: \u0026#34;\u0026#34;\u0026#34; # susan算子 susan_operator = np.ones((7, 7)) susan_operator[0, 0] = 0 susan_operator[0, 1] = 0 susan_operator[0, 5] = 0 susan_operator[0, 6] = 0 susan_operator[1, 0] = 0 susan_operator[1, 6] = 0 susan_operator[5, 0] = 0 susan_operator[5, 6] = 0 susan_operator[6, 0] = 0 susan_operator[6, 1] = 0 susan_operator[6, 5] = 0 susan_operator[6, 6] = 0 dst = img.astype(np.float64) # 检测阈值 threshold = 37 / 2 # 像素偏差阈值 t = 10 for i in range(3, dst.shape[0] - 3): for j in range(3, dst.shape[1] - 3): # ir：中心位置像素，ir0周边位置像素 # 获取矩形区域 ir = np.array(dst[i - 3:i + 4, j - 3:j + 4]) # 使用susan算子截取圆形区域 ir = ir[1 == susan_operator] ir0 = dst[i, j] # 平滑曲线相似变换：c = e的[-((ir - ir0)/6))的6次方]的次方，表示相似还是不相似 similarity = np.sum(np.exp(-((ir - ir0) / t) ** 6)) # 小于阈值，提取特征点 if similarity \u0026lt; threshold: img[i, j, 2] = 255 return img def feature_point_detection_harris(img: np.ndarray): \u0026#34;\u0026#34;\u0026#34; harris特征点检测 :param img: :return: \u0026#34;\u0026#34;\u0026#34; # 转换为灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Harris特征点检测 # 检测窗口大小 block_size = 2 # Sobel的卷积核 k_size = 3 # 权重系数 k = 0.04 dst = cv2.cornerHarris(gray, block_size, k_size, k) # 在原图上绘制关键点 img[dst \u0026gt; 0.01 * dst.max()] = [0, 0, 255] return img def feature_point_detection_sift(img: np.ndarray): \u0026#34;\u0026#34;\u0026#34; sift特征点检测 :param img: :return: \u0026#34;\u0026#34;\u0026#34; # 转换为灰度图 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 创建SIFT对象 sift = cv2.SIFT_create() # SIFT关键点检测 kernel_point = sift.detect(gray, None) # 在原图绘制关键点 cv2.drawKeypoints(gray, kernel_point, img) return img def image_show(img: np.ndarray, title=\u0026#39;img\u0026#39;): \u0026#34;\u0026#34;\u0026#34; 显示图片 :param img: :param title: :return: \u0026#34;\u0026#34;\u0026#34; cv2.namedWindow(title) cv2.imshow(title, img) cv2.waitKey(0) def feature_point(path: str, kernel_method=\u0026#39;susan\u0026#39;): # 读取图片 img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR) # 特征检测 if \u0026#39;susan\u0026#39; == kernel_method: img_feature_point = feature_point_detection_susan(img) elif \u0026#39;harris\u0026#39; == kernel_method: img_feature_point = feature_point_detection_harris(img) elif \u0026#39;sift\u0026#39; == kernel_method: img_feature_point = feature_point_detection_sift(img) else: img_feature_point = feature_point_detection_susan(img) # 显示图片 image_show(img_feature_point, kernel_method) 三：实验结果及分析 （一）边缘提取 （1）实验原图 （2）robert算子 提取时间：0.0020003318786621094\r（3）prewitt算子 提取时间：0.0010013580322265625\r（3）sobel算子 提取时间：0.002001523971557617\r（4）laplacian算子 提取时间：0.001997232437133789\r（5）综合对比 robert提取时间：0.0020003318786621094 prewitt提取时间：0.0010013580322265625 sobel提取时间：0.002001523971557617 laplacian提取时间：0.001997232437133789 通过上图可以看出，laplacian二阶算子的边缘提取算子的提取效果明显优于robert，prewitt，sobel等一阶算子。且一阶算子和二阶算子在提取的时间上和算法的复杂度上相差不大，所以在实验中，如果有特征提取需求的话，可以尽量多采用二阶算子进行边缘提取。\n（二）特征点检测 （1）实验原图 （2）susan特征点检测 （3）harris特征点检测 （4）sift特征点检测 （5）综合对比 在实验中，因为opencv不提供（或本人没有找到）有关susan的特征点检测的函数，所以susan特征点检测是自己写的，相比于其他特征点检测直接调用底层库较慢。在三个检测图片中，可以发现sift特征点检测检测到的特征点更多，其他检测是边缘特征点，二sift不仅检测了边缘特征点，也检测出了中心特征点。\n","date":"2022-11-16T00:00:00Z","permalink":"/post/opencv/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E9%AA%8C%E8%BE%B9%E7%BC%98%E6%8F%90%E5%8F%96%E4%B8%8E%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B/","title":"计算机视觉实验：边缘提取与特征检测"},{"content":"计算机网络的概念、组成与功能 计算机网络的概念 计算机网络：计算机网络是一个将分散的、具有独立功能的计算机系统，通过通信设备与线路连接起来，由功能完善的网络软件（即网络通信协议、信息交换方式、网络操作系统等）实现网络中资源共享和信息传递的系统。 简而言之：计算机网络就是一些互联的、自治的计算机系统的集合。\n计算机网络的组成 组成部分 一个完整的计算机网络主要由硬件、软件、协议三大部分组成\n硬件： 主机（也称端系统） 通信链路（如双绞线、光纤等） 交换设备（如路由器、交换机等） 通信处理机（如网卡等） 软件： 实现资源共享的软件 方便用户使用的工具软件 软件在计算机网络中多属于应用层 协议： 计算机网络的核心 规定了网络传输数据时所遵循的规范 工作方式 从工作方式来看，计算机网络（这里主要指因特网，Internet）可分为边缘部分和核心部分。\n边缘部分：由所有连接到因特网上、供用户直接使用的主机组成 用来进行通信（传输数据、音频或视频） 进行资源共享 核心部分：由大量的网络和连接这些网络的路由器组成 为边缘部分提供连通性和交换服务 功能组成 从功能组成上看，计算机网络主要由通信子网和资源子网组成。\n通信子网：由各种传输介质、通信设备和相应的网络协议组成 使网络具有数据传输、交换、控制和存储能力 实现联网计算机的数据通信 资源子网：实现资源共享功能的设备及其软件的集合 向网络用户提供共享在其他计算机上的硬件资源、软件资源和数据资源服务 计算机网络的功能 计算机网络主要有以下五大功能：\n数据通信：用来实现联网计算机之间各种信息的传输，并将分散在不同地理位置的计算机联系起来，进行统一的调配、控制和管理。 计算机网络最基本和最重要的功能。 资源共享：使计算机网络中的资源相互联通、分工协作，从而提高硬件资源、软件资源和数据资源的利用率。 计算机网络资源主要分为：硬件资源、软件资源和数据资源。 分布式处理：当计算机网络中的某个计算机系统负载过高时，可以将其处理的某个复杂任务分配给网络中的其他计算机系统，利用空闲计算机资源提高整个系统的利用率。 提高可靠性：计算机网络中的多台计算机可以通过网络互为替代机。 负载均衡：将工作任务均衡的分配给计算机网络中的各个计算机。 计算机网络的分类 分布范围 广域网（WAN）：也称远程网 提供长距离通信 是因特网的核心。 覆盖范围通常是直径为几十千米到几千千米的区域 各结点交换机的链路一般是高速链路，具有较大的通信容量 使用交换技术 城域网（MAN）： 覆盖范围可以跨越几个街区甚至整个城市 盖区域的直径范围是5~50km 采用以太网技术，所以常并入局域网的范围讨论 局域网（LAN）： 覆盖范围较小，通常是直径几十米到几千米的区域 传统的局域网使用广播技术 个人区域网（PAN）：也称无线个人区域网（WPAN） 个人工作的地方将消费电子设备用无线技术连接起来的网络 覆盖区域直径约为10m 传输技术 广播式网络：所有联网计算机都共享一个公告通信信道。当一台计算机利用共享通信信道发送报文分组时，其他计算机都会“收听”这个分组。接受到该分组的计算机通过检查目的地址决定是否接收该分组。 局域网：广播式通信技术 广域网中的无线、卫星通信网络：广播式通信技术 点对点网络：每条物理线路连接一对计算机主机。若通信的两天主机之间没有直接连接的线路，则它们之间的分组传输就要通过中间结点进行接收、存储和转发，直到目的结点。 广域网：基本采用点对点通信技术 拓扑结构 网络拓扑结构是指由网络中结点（主机、路由器）与通信线路（网线）之间的几何关系表示的网络结构，主要指通信子网的拓扑结构。\n总线型网络：用单根传输线把计算机连接起来。 优点：建网容易、增删结点方便、节省线路 缺点：重负载时通信效率不高、总线对故障敏感 多用于局域网 星型网络：每个终端或计算机都以单独的线路与中央设备相连。 优点：便于控制和管理，端用户之间通信必须经过中央设备 缺点：成本高、中央设备对故障敏感 多用于局域网 环形网络：所有计算机设备连接成一个环。 环中信号是单向传输 多用于局域网 网状网络：每个结点至少有两条路径与其他结点相连，组成一个网。 有规则型和非规则型两种 优点：可靠性高 缺点：控制复杂、线路成本高 多用于广域网 使用者 公用网（Public Network）：电信公司出资建造的大型网络。按电信公司规定交纳费用的人都可以使用。 专用网（Privat Network）：某个部门或机构为满足本单位特殊业务需要而建造的网络。这种网络不向外人提供服务。 交换技术 交换技术：交换技术是指各台主机之间、各通信设备之间或主机与通信设备之间为交换信息所采用的数据格式和交换装置的方式。\n电路交换网络：在源结点和目的结点之间建立一条专用的通路用于传送数据，包括建立连接、传输数据和断开连接三个阶段。 特点：整个报文的比特流连续的从源结点直达目的结点。 优点：数据直接传输、时延小。 缺点：线路利用率低、不能充分利用线路容量、不便于进行差错控制。 报文交换网络（存储-转发网络）：用户数据加上源地址、目的地址、校验码等辅助信息，然后封装称报文，整个报文传送到相邻的结点。全部存储后，再转发给下一个结点，重复这一过程直到到达目的结点。 每个报文可以单独选择到达目的结点的路径。 特点：整个报文先传送到相邻结点，全部存储后查找转发表，转发到下一个结点。 优点： 较充分的利用线路容量 实现不同链路之间不同数据传输速率的转换 实现格式转换 实现一对多、多对一的访问 实现差错控制 缺点： 增大了资源开销（存储报文信息） 增大了缓冲时延 需要额外机制保证报文不乱序 缓冲区难以管理 分组交换网络（包交换网络）：将数据分为较短的固定长度的数据块，在每个数据块上加上目的地址、源地址等辅助信息组成分组（包），以存储-转发方式传输。 特点：以单个分组（整个报文的一小部分）传送到相邻结点，存储后查找转发表，转发到下一结点。 优点： 具有报文交换网络的所有优点 缓冲易于管理 包的平均时延更小 网络占用的平均缓冲区更少 更易于标准化 更易于应用 主流网络基本都使用分组交换网络 传输介质 有线：分为双绞线、同轴电缆网络等 无线：蓝牙、微波、无线电等类型 计算机网络的标准化工作及相关组织 计算机网络的标准化工作 因特网的所有标准都以RFC（Request For Comments）是形式在因特网上发布，RFC要上升为因特网正式标准需要经过以下4各阶段。\n因特网草案：这个阶段还不是RFC文档 建议标准：从这个阶段开始成为RFC文档 草案标准 因特网标准 计算机网络的标准化工作的相关组织 国际标准化组织（ISO）：主要标准或规范有OSI参考模型，HDLC协议等。 国际电信联盟（ITU）： 前身是国际电话电报咨询委员会（CCITT） 下属机构ITU-T制定了大量有关远程通信的标准 国际电气电子工程师协会（IEEE）：世界上最大的专业技术团队，由计算机和工程学专业人士组成。 计算机网络体系结构与参考模型 体系结构（Architecture）：计算机网络的各层及其协议的集合称为体系结构。它是计算机网络中的各层次、各层的协议及层间接口的集合。\n计算机网络分层结构 两个系统中实体间通信是一个复杂的过程，为了降低系统的复杂度，通常对计算机网络的体系结构进行分层，每层处理执行不同的功能以降低系统的复杂度。\n计算机网络分层的基本原则 每层都实现一种相对独立的功能，降低系统的复杂度 各层之间界面自然清晰，易于理解，相互交流尽可能少 各层功能的精确定义独立于具体的实现方法，可以采用最合适的技术来实现 保持下层对上层的独立性，上层单向使用下层提供的服务 整个分层结构应能促进标准化工作 计算机网络层次结构基本概念与术语 按照一定规则，将分层后的网络从低到高依次称为第1层、第2层$\\cdots$第$n$层。 在分层结构中，第$n$层的活动元素通常称为第$n$层实体。 不同机器上的同一层称为对等层，同一层的实体称为对等实体。 第$n$层实体实现的服务为第$n + 1$层所利用，第$n$层称为服务提供者，第$n + 1$层则服务于用户。\n报文 在计算机网络系统结构的各个层次中，每个报文都分为两部分：一是数据部分（SDU）；二是控制信息部分（PCI），它们共同组成PDU。\n服务数据单元（SDU，Service Data Unit）：为完成用户所要求的功能而应发送的数据。 n-SDU：第$n$层服务数据单元称为n-SDU。 协议控制信息（PCI，Protocol Control Information）：控制协议操作的信息。 n-PCI：第$n$层协议控制信息称为n-PCI。 协议数据单元（PDU，Protocol Data Unit）：对等层次之间传送的数据单位称为该层的PDU。 n-PDU：第$n$层协议数据单元称为n-PDU。 物理层PDU：比特 数据链路层PDU：帧 网络层PDU：分组 传输层PDU：报文段 在各层传输数据时，把从第$n + 1$层收到的PDU作为第$n$层的SDU，加上第$n$层的PCI，就变成了第$n$层的PDU，交给第$n - 1$层后作为SDU发送，接收方接收时做相反的处理，因此三者的关系为：$n-SDU + n-PCI = n-PDU = (n - 1)-SDU$\n计算机网络层次结构的含义 第$n$层的实体不仅要使用第$n - 1$层的服务来实现自身定义的功能，还要向第$n + 1$层提供本层的服务，该服务是第$n$层及其下面各层提供服务的总和。 最低层只提供服务，是整个层次结构的基础；中间各层既是下一层的服务使用者，又是上一层的服务提供者；最高层面向用户提供服务。 上一层只能通过相邻层间的接口使用下一层的服务，不能调用其他层的服务；下一层所提供的服务的实现细节对上一层透明。 两条主机通信时，对等层在逻辑上有一条直接信道，表示为不经过下层就能把信息传送给对方。 计算机网络协议、接口、服务等概念 协议 协议：指规则的集合，是对等实体之间为通信制定的有关通信规则约定的集合。 协议的三要素：\n语法：规定了传输数据的格式。 语义：规定了所要完成的功能，即需要发出何种控制信息、完成何种动作及做出何种应答。 同步：规定了执行各种操作的条件、时序关系等，即事件实现顺序的详细说明。 接口（服务访问点，SAP） 接口（服务访问点，SAP，Service Access Point）：是同一系统中相邻两层的实体进行交互的连接点。每层只能为紧邻的层次定义接口，不能跨层次定义接口。\n服务 服务：为保证上层对等实体之间的相互通信，下层为上层提供的功能。它是垂直的，在协议的控制下，本层为上层提供服务，同时实现本层协议还需要使用下一层提供的服务。\n服务原语 上层使用下层所提供的服务时必须与下层交换一些命令，这些命令在OSI参考模型中称为服务原语。\nOSI参考模型将原语划分为4类：\n请求（Request）：由服务用户发往服务提供者，请求完成某项工作。 指示（Indication）：由服务提供者发往服务用户，指示用户做某件事情。 响应（Response）：由服务用户发往服务提供者，作为对指示的响应。 证实（Confirmation）：由服务提供者发往服务用户，作为对请求的证实。 服务分类 面向连接服务与无连接服务 面向连接服务：通信前双方必须先建立连接，分配相应的资源，以保证通信的正常进行，传输结束后释放连接和所占用的资源。 面向连接服务分为：建立连接、数据传输、连接释放三个阶段 TCP是典型的面向连接服务协议 无连接服务：通信前双方不需要先建立连接，需要发送数据时可直接发送，把每个带有目的地址的报文传送到线路上，由系统选定路线进行传输。 是不可靠的服务 尽最大努力交付（Best-Effort-Delivery）：并不保证通信的可靠性 IP、UDP是典型的无连接服务协议 可靠服务和不可靠服务 可靠服务：可靠服务指网络具有纠错、检错、应答机制，能保证数据正确的，可靠地传送到目的地。 不可靠服务：网络尽量正确、可靠地传送，不能保证数据正确、可靠地传送到目的地，是一种尽力而为的服务。 不可靠服务网络的正确性、可靠性要由应用或用户来保障 有应答服务和无应答服务 有应答服务：接收方收到数据后向发送方给出相应的应答，该应答由传输系统内部自动实现，而不由用户来实现。 拥有请求、指示、响应和证实全部4类原语 无应答服务：接收方收到数据后不自动给出应答。若需要应答，由高层实现。 只有请求和指示两类原语 ISO/OSI 参考模型和 TCP/IP 模型 开放系统互连参考模型（OSI参考模型） 国际标准化组织（ISO）提出的网络体系结构模型，称为开放系统互连参考模型（OSI/RM），统称为OSI参考模型。 OSI参考模型有7层，从下到上分别为：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。低三层统称为通信子网，为了联网而附加的通信设备，完成数据的传输功能；高三层统称为资源子网，相当于计算机系统，完成数据的处理功能。传输层起到承上启下的作用。\n物理层（Physical Layer）：数据终端设备（DTE）和数据通信设备（DCE）的物理与逻辑连接方法。\n传输单位：比特 任务：透明地传输比特流 功能：在物理媒体上为数据端设备透明地传输原始比特流 研究内容： 通信链路与通信结点的连接需要电路接口，物理层规定了这些接口的参数，如机械形状和尺寸、交换电路的数量和排列等 物理层规定了通信链路上传输的信号的意义和电气特征 数据链路层（Data Link Layer）：\n传输单位：帧 任务：将网络层传来的IP数据组装成帧 功能：组装成帧、差错控制、流量控制和传输管理 典型协议：HDLC、PPP、ADSL等 提供点到点（主机到主机）之间的通信 网络层（Network Layer）：\n传输单位：数据报 任务：把网络层的协议数据单元（分组）从源端传送到目的端，为分组交换网上的不同主机提供通信服务 功能：路由选择、流量控制、拥塞控制、差错控制和网络互联 典型协议：IP、ICMP、IGMP、ARP等 传输层（Transport Layer）：\n传输单位：报文段（TCP）或数据报（UDP） 任务：负责主机中两个进程之间的通信 功能：为端到端连接提供可靠传输服务、为端到端连接提供流量控制、差错控制、服务质量、数据传输管理等服务 典型协议：TCP、UDP 提供端到端（进程与进程）之间的通信 会话层（Session Layer）：\n允许不同主机各个进程之间进行会话。 会话（建立同步，SYN）：表示层实体或用户进程建立连接并在连接上有序地传输数据的过程。 功能： 管理主机间的会话进程 数据同步：使用校验点使通信失效时可以从校验点继续恢复通信 表示层（Presentation Layer）：\n任务：处理两个通信系统中交换信息的表示方式 功能：数据压缩、加密和解密，数据表示变换 应用层（Application Layer）：\n为特定类型的网络应用提供访问OSI参考模型环境的手段 典型协议：FTP、SMTP、HTTP等 TCP/IP模型 ARPA在研究ARPAnet时提出的TCP/IP模型，模型从低到高依次为网络接口层（对应OSI参考模型的物理层和数据链路层）、网际层、传输层和应用层（对应OSI参考模型的会话层、表示层和应用层）。TCP/IP以模型中两个最主要的协议命名，应广泛使用已成为事实上的国际标准。\n网络接口层： 类似于OSI参考模型的物理层和数据链路层 作用：从主机或结点接收IP分组，并把它们发送到指定的物理网络上 网际层（主机-主机）： 类似于OSI参考模型的网络层 作用：将分组发往任何网络，并为之独立地选择合适的路由，但不保证各个分组有序地到达，各个分组有序的交付由高层负责 典型协议：IP 传输层（应用到应用或进程到进程）： 类似于OSI参考模型的传输层 作用：使得发送端和目的端主机上的对等实体进行会话 典型协议： 传输控制协议（Transmission Control Protocol，TCP）：面向连接的，数据传输的单位是报文段，能够提供可靠的交付。 用户数据报协议（User Datagram Protocol，UDP）：无连接的，数据传输的单位是数据报，不保证可靠交付，只能提供“尽最大努力交付”。 应用层（用户到用户）： 类似于OSI参考模型的会话层、表示层和应用层 OSI参考模型和TCP/IP模型的比较 相同点 都采用分层的体系结构，将复杂的问题划分为若干较容易的问题，分层的功能大体相似 都是基于独立的协议栈的概念 二者都可以解决异构网络的互连，实现不同厂家生产的计算机之间的通信 不同点 OSI参考模型精确地定义了三个主要概念：协议、服务和接口，符合现代面向对象程序设计思想；TCP/IP在概念上没有明确区分 OSI参考模型产生协议之前没有偏向特定协议，通用性良好；TCP/IP首先出现的是协议，模型实际上是对已有协议的描述 OSI参考模型最初只考虑一种标准的公用数据网将各种不同的系统互连，在认识到IP的重要性后，将网络层划分出一个子层完成类似于IP的功能；TCP/IP模型在设计之初就考虑到了多种异构网的互联问题，并将IP作为一个单独的重要层次 OSI参考模型在网络层支持无连接和面向连接的通信，但在传输层仅有面向连接的通信；TCP/IP认为可靠性是端到端的问题，在网际层仅有一种无连接的通信模式，但在传输层支持无连接和面向连接两种模式。 ","date":"2022-09-27T00:00:00Z","permalink":"/post/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","title":"计算机网络体系结构"},{"content":"常见视频传输协议 协议 httpflv rtmp rtsp hls dash 传输方式 http流 tcp流 tcp流 http http 视频封装格式 flv flv tag ts mp4 Ts文件 Mp4 3gp webm 延时 低 低 低 高 高 数据分段 连续流 连续流 连续流 切片文件 切片文件 Html5播放 可通过html5解封包播放(flv.js) 不支持 不支持 可通过html5解封包播放(hls.js) 如果dash文件列表是mp4webm文件，可直接播放 监控行业常见的视频传输协议：RTSP，RTMP（以RTSP流为主）\nRTSP与RTMP比较 RTSP：低时延，实现难度大，适合视频聊天和视频监控 RTMP：浏览器支持好，加载flash插件后能直接播放（高版本浏览器目前已禁止flash插件） 直播常见协议：RTMP，HTTP RTMP：只支持flashplayer，目前已被淘汰 HTTP：flv，m3u8，ts flv：flash video，需要flash支持，使用flv.js可支持播放（B站视频） m3u8：切片文件，有延迟，实时性不如RTSP协议，如果压缩过小，可能导致客户端网络原因变卡，如果压缩过大，可能导致视频延迟过高 ts：切片文件，同m3u8 ","date":"2022-06-15T00:00:00Z","permalink":"/post/opencv/%E8%A7%86%E9%A2%91%E6%B5%81%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/","title":"视频流传输协议"},{"content":"使用VideoCapture读取视频流 在使用OpenCv处理视频时，无论是视频文件还是摄像头画面，都要使用VideoCapture类来进行每一帧图像的处理。当我们使用视频文件作为参数时，OpenCv则打开视频文件，进行每一帧画面的读取。当我们传递摄像机编号时，OpenCv则打开相机，实时读取相机画面。\n获取VideoCaptrue实例：\n1 2 3 4 # 读取视频文件 cv2.VideoCapture(\u0026#39;video.mp4\u0026#39;) # 打开摄像机 cv2.VideoCapture(0) 使用VideoCapture读取海康RTSP流 RTSP流 在使用OpenCv进行计算机视觉处理时，我们很多时候需要连接外部相机，如海康威视。监控相机的常见视频传输协议有：RTSP、RTMP（以RTSP为主） RTSP与RTMP比较：\nRTSP：低时延，实现难度大，适合视频聊天和视频监控 RTMP：低时延，实现难度大，适合视频聊天和视频监控 目前市面上的相机大多以RTSP流协议为主。 在读取海康相机时，需要使用VideoCapture读取RTSP流协议的内容，而不是通过相机编号直接读取。\n1 2 3 4 5 6 7 8 9 10 \u0026#34;\u0026#34;\u0026#34; 海康相机rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 \u0026#34;\u0026#34;\u0026#34; 使用VideoCapture读取RTSP流示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 使用rtsp流打开相机 def open_camera(username: str, password: str, ip: str, port: int): \u0026#34;\u0026#34;\u0026#34; 使用rtsp流打开相机 rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 :return:相机是否打开，相机 \u0026#34;\u0026#34;\u0026#34; try: # 使用rtsp流打开相机 cam = cv2.VideoCapture(f\u0026#39;rtsp://{username}:{password}@{ip}:{port}/h264/ch1/main/av_stream\u0026#39;) return True, cam except cv2.error: # 捕获cv异常 # 打开相机失败 return False, None ping3 在使用RTSP流读取相机内容时，若IP错误，或相机连接异常，则VideoCapture无法访问相机，VideoCapture实例访问超时且程序异常，在使用PyQt等GUI程序中，程序可能出现异常闪退情况，所以在连接RTSP流前，请先对相机IP进行预校验，减少出错概率。可以在访问相机之前，通过ping 相机IP的方式来对IP进行预校验。 在Python中可以使用ping3库对IP进行ping测试。\nping3.ping成功默认返回秒为单位 ping3.ping参数错误返回False ping3.ping失败时返回None ping3.ping函数返回说明：\nReturns: The delay in seconds/milliseconds, False on error and None on timeout.\nping3.ping示例：\n1 2 3 4 5 6 import ping3 if __name__ == \u0026#39;__main__\u0026#39;: print(ping3.ping(\u0026#39;focus-wind.com\u0026#39;)) print(ping3.ping(\u0026#39;https://focus-wind.com\u0026#39;)) print(ping3.ping(\u0026#39;192.168.1.64\u0026#39;)) ping3.ping运行结果：\n1 2 3 4 5 6 # ping focus-wind.com ping成功 0.03125762939453125 # ping https://focus-wind.com 参数异常 False # ping 192.168.1.64 无法访问对应IP None 完整访问RTSP流示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def open_camera(username: str, password: str, ip: str, port: int = 554): \u0026#34;\u0026#34;\u0026#34; 使用rtsp流打开相机 rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 :return:相机是否打开，相机 \u0026#34;\u0026#34;\u0026#34; try: # ping IP，IP预检验 if ping3.ping(ip) is None or not ping3.ping(ip): # ping的结果为None或False，ping失败，不存在该IP return False, None else: # 使用rtsp流打开相机 cam = cv2.VideoCapture(f\u0026#39;rtsp://{username}:{password}@{ip}:{port}/h264/ch1/main/av_stream\u0026#39;) return True, cam except cv2.error: # 捕获cv异常 # 打开相机失败 return False, None 获取视频流信息 一般视频流的信息主要包含画面的宽高以及视频显示帧率，对于视频文件，还包括总共有多少帧画面。针对这些信息，我们可以使用VideoCapture类的get方法获取相关信息。\n1 2 3 4 5 6 7 8 # 获取视频帧的宽 width = cam.get(cv2.CAP_PROP_FRAME_WIDTH) # 获取视频帧的高 height = cam.get(cv2.CAP_PROP_FRAME_HEIGHT) # 获取视频帧的帧率 fps = cam.get(cv2.CAP_PROP_FPS) # 获取视频文件的总帧数 frame_count = cam.get(cv2.CAP_PROP_FRAME_COUNT) 针对获取总帧数函数，若相机不支持获取总帧数，则返回0，获取总帧数仅对视频文件有意义。\n获取帧画面 直接调用VideoCapture类的read方法，read方法会返回两个参数，一个为是否成功标志，一个为帧画面。 read方法返回参数：\n成功，BGR格式的numpy.ndarray三维数组 失败，None read使用示例：\n1 2 # 获取帧画面 ret, frame = cam.read() 在调用read方法时，有时候可能会访问失败，所以为避免访问失败，可以采用while循环确保读取顺利。\n1 2 3 4 5 # 获取帧画面 ret, frame = cam.read() # 循环读取，确保读取成功 while not ret: ret, frame = cam.read() 读取帧画面优化 OpenCv底层基于ffmpeg读取视频，在OpenCv读取视频流时，会设置缓存区，将视频流读取到缓存区中，但是使用缓存区的话，会导致页面堆积，页面延迟高过，所以为了避免OpenCv缓存区视频流堆积的情况，可以使用线程实时读取OpenCv画面，将读取的每一帧内容存在队列中，在需要获取帧画面时，获取队列中的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 import queue import threading import cv2 class CameraThread(threading.Thread): # 保存实例化相机，通过实例化相机操作相机 camera = None # 保存每一帧从rtsp流中读取到的画面 queue_image = queue.Queue(maxsize=10) # 线程体是否循环执行标志 flag_run = False # 相机线程调用函数 def run(self) -\u0026gt; None: while self.flag_run: try: # 捕获异常，避免读取视频操作因异常而退出 # 相机实例存在，判断相机是否打开 if self.camera.is_opened(): # 相机已打开，读取相机内容 ret, frame = self.camera.read() if not ret or frame is None: # 读取相机内容失败 break if ret: # 将内容添加到队列中 # 判断队列是否满 if self.queue_image.full(): # 队列满，队头出队 self.queue_image.get() # 队尾添加数据 self.queue_image.put(frame) else: # 队尾添加数据 self.queue_image.put(frame) except cv2.error as error: # 捕获cv异常 # 因为子线程会一直调用该程序，可对捕获到的异常不进行处理 print(error) pass except Exception as error: # 捕获Exception异常 print(error) pass # setter：设置相机的camera对象 def set_camera(self, camera): \u0026#34;\u0026#34;\u0026#34; 设置相机的camera对象 \u0026#34;\u0026#34;\u0026#34; # 设置相机的camera self.camera = camera # 获取队列中的RGB图像 def get_image(self): \u0026#34;\u0026#34;\u0026#34; 获取队列中的RGB图像 :return: img: RGB图像 \u0026#34;\u0026#34;\u0026#34; # 读取队列中的图片 img = self.queue_image.get() # img为None，读取失败，队列还未获取到图片 while img is None: # 一直读取图片，直到读取图片成功 img = self.queue_image.get() # 返回读取到的内容 return img # 停止运行 def run_stop(self): self.flag_run = False # 开始运行 def run_start(self): self.flag_run = True ","date":"2022-06-03T00:00:00Z","permalink":"/post/opencv/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%A7%86%E9%A2%91%E6%B5%81%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/","title":"基于OpenCv的视频流处理方法"},{"content":"问题： 在使用cv2.imshow()显示图片时，只能显示图片的部分内容，无法完全显示图片内容。\n原因： 查看cv2.imshow()函数说明可知，opencv在使用cv2.imshow()显示图片时，是在指定窗口中显示图片，若在调用cv2.imshow()函数之前，没有调用创建窗口的函数，则默认使用cv2.WINDOW_AUTOSIZE标记创建默认窗口，如果需要显示大于屏幕分辨率的图像，则需要在使用cv2.imshow()之前调用cv2.namedWindow(\u0026quot;\u0026quot;, cv2.WINDOW_NORMAL)\nIf the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE. 如果该窗口不是在此函数之前创建的，则假定使用cv:：WINDOW_AUTOSIZE创建窗口。\nIf you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\u0026quot;\u0026quot;, WINDOW_NORMAL) before the imshow. 如果需要显示大于屏幕分辨率的图像，则需要在imshow之前调用namedWindow(\u0026quot;\u0026quot;, WINDOW_NORMAL)。\n解决方法： 在使用cv2.imshow()之前，调用cv2.namedWindow()函数，设置显示窗口属性。若调用cv2.namedWindow()函数图片仍显示不全，可调用cv2.resize()函数使图片的分辨率在显示屏的分辨率也可使图片完全显示。\n示例： 直接调用imshow()显示图片：\n1 2 3 4 5 6 7 import cv2 import numpy as np if __name__ == \u0026#39;__main__\u0026#39;: img = cv2.imdecode(np.fromfile(r\u0026#39;C:\\Users\\focus\\Pictures\\背景图片\\希望之鲸.jpg\u0026#39;, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.imshow(\u0026#39;img\u0026#39;, img) cv2.waitKey(0) 设置namedWindow()：\n1 2 3 4 5 6 7 8 import cv2 import numpy as np if __name__ == \u0026#39;__main__\u0026#39;: img = cv2.imdecode(np.fromfile(r\u0026#39;C:\\Users\\focus\\Pictures\\背景图片\\希望之鲸.jpg\u0026#39;, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.namedWindow(\u0026#39;img\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;img\u0026#39;, img) cv2.waitKey(0) ","date":"2022-05-16T00:00:00Z","permalink":"/post/opencv/opencv-cv2.imshow%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%E4%B8%8D%E5%85%A8/","title":"OpenCv-cv2.imshow()显示图片不全"},{"content":"使用OpenCv捕获摄像机画面后，我们有时候需要将画面显示在界面上。本博客基于Django的前后端分离模式，将视频流从后端读取，传送给前端显示。\nDjango流传输实例：StreamingHttpResponse 在使用Django进行视频流传输时，无法使用HttpResponse，JsonResponse等对象对内容直接传输，需要使用StreamingHttpResponse流式传输一个响应给浏览器。StreamingHttpResponse不是HttpResponse的子类，因此他们之间的API略有不同。StreamingHttpResponse与HttpResponse之间有以下显著区别：\n应该给StreamingHttpResponse一个迭代器，产生字节字符串作为内容。 不应该直接访问StreamingHttpResponse的内容，除非通过迭代器响应对象本身。 StreamingHttpResponse没有content属性。相反，他有一个streaming_content属性。 无法使用类文件对象的tell()何write()方法。这样会引起一个异常。 Django传输视频流 因为使用Django的StreamingHttpResponse类进行流传输，所以我们首先需要生成一个视频流的迭代器，在迭代器中，需要将从opencv中获取到的numpy.ndarray三维数组转换为字节类型的，然后传输到前端。\n传输视频流：\n读取图片 图片压缩（针对分辨率较高的界面） 对图片进行解码 转换为byte类型 传输视频流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import cv2 from django.http import StreamingHttpResponse def gen_display(camera): \u0026#34;\u0026#34;\u0026#34; 视频流生成器功能。 \u0026#34;\u0026#34;\u0026#34; while True: # 读取图片 ret, frame = camera.read() if ret: # 将图片进行解码 ret, frame = cv2.imencode(\u0026#39;.jpeg\u0026#39;, frame) if ret: # 转换为byte类型的，存储在迭代器中 yield (b\u0026#39;--frame\\r\\n\u0026#39; b\u0026#39;Content-Type: image/jpeg\\r\\n\\r\\n\u0026#39; + frame.tobytes() + b\u0026#39;\\r\\n\u0026#39;) def video(request): \u0026#34;\u0026#34;\u0026#34; 视频流路由。将其放入img标记的src属性中。 例如：\u0026lt;img src=\u0026#39;https://ip:port/uri\u0026#39; \u0026gt; \u0026#34;\u0026#34;\u0026#34; # 视频流相机对象 camera = cv2.VideoCapture(0) # 使用流传输传输视频流 return StreamingHttpResponse(gen_display(camera), content_type=\u0026#39;multipart/x-mixed-replace; boundary=frame\u0026#39;) 在使用海康威视等分辨率较高的相机时，直接解码，延迟过高，所以需要先对图片进行压缩，然后解码。\n经测试，海康相机使用0.25的压缩倍率显示压缩效率较好，当大于0.25时，延迟较高，小于0.25时，界面显示较差\n迭代器优化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def gen_display(camera): \u0026#34;\u0026#34;\u0026#34; 视频流生成器功能。 \u0026#34;\u0026#34;\u0026#34; while True: # 读取图片 ret, frame = camera.read() if ret: frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25) # 将图片进行解码 ret, frame = cv2.imencode(\u0026#39;.jpeg\u0026#39;, frame) if ret: # 转换为byte类型的，存储在迭代器中 yield (b\u0026#39;--frame\\r\\n\u0026#39; b\u0026#39;Content-Type: image/jpeg\\r\\n\\r\\n\u0026#39; + frame.tobytes() + b\u0026#39;\\r\\n\u0026#39;) 前端显示视频流 在Django中配置路由后，在浏览器端直接访问视频url即可看到视频显示画面。 在前端HTML5中，将视频路由写入img标签的src属性中，即可访问视频流界面。例如：\u0026lt;img src=\u0026lsquo;https://ip:port/uri\u0026rsquo; 前端显示视频流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;基于OpenCv+Django的网络实时视频流传输（前后端分离）\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- 显示视频流 --\u0026gt; \u0026lt;img src=\u0026#34;http://127.0.0.1:8000/api/cv/display\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 显示结果：\n在前端显示视频流中，可以通过调整img标签的属性来调整界面显示位置，显示大小。所以在进行视频流前后端传输中，在保证视频显示清晰度的情况下，建议使用前端来调整界面大小。\n调整界面前端显示视频样式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;基于OpenCv+Django的网络实时视频流传输（前后端分离）\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; #video { width: 500px; height: 500px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- 显示视频流 --\u0026gt; \u0026lt;div align=\u0026#34;center\u0026#34;\u0026gt;\u0026lt;img src=\u0026#34;http://127.0.0.1:8000/api/cv/display\u0026#34; id=\u0026#34;video\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 显示结果：\n视频流传输优化 在项目中，我们可能经常需要对多个相机进行处理，而不是对一个相机进行操作，所以我们可以使用相机工厂来获取相机。在实例化相机后，需要开启一个线程，及时更新缓存队列，确保OpenCv不会因为缓存过多而造成缓存区堵塞，界面延迟。\n使用线程实时读取OpenCv的内容到队列中 使用相机工厂来获取相机 在示例代码中，camera_model为自定义model，其中代码需要用到的数据有数据表记录的唯一标识id，相机的访问api：camera_api\n相机类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import queue import threading import cv2 from apps.device.models import Camera class CameraException(Exception): message = None # 初始化异常 def __init__(self, message: str): # 初始化异常，定位异常信息描述 self.message = message def __str__(self): return self.message class BaseCamera: # 相机操作对象 cam = None # 保存每一帧从rtsp流中读取到的画面，使用opencv读取，为BGR图片 queue_image = queue.Queue(maxsize=10) # 后台取帧线程 thread = None # 相机Model camera_model = None # 相机基类 def __init__(self, camera_model: Camera): \u0026#34;\u0026#34;\u0026#34; 使用rtsp流初始化相机参数 rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 \u0026#34;\u0026#34;\u0026#34; self.cam = cv2.VideoCapture(camera_model.camera_api) if self.cam.isOpened(): # 相机打开成功,启动线程读取数据 self.thread = threading.Thread(target=self._thread, daemon=True) self.thread.start() else: # 打开失败，相机流错误 raise CameraException(\u0026#34;视频流接口访问失败\u0026#34;) def _thread(self): \u0026#34;\u0026#34;\u0026#34; 相机后台进程，持续读取相机 opencv读取时会将信息存储到缓存区里，处理速度小于缓存区速度，会导致资源积累 \u0026#34;\u0026#34;\u0026#34; # 线程一直读取视频流，将最新的视频流存在队列中 while self.cam.isOpened(): ret, img = self.cam.read() if not ret or img is None: # 读取相机失败 pass else: # 读取内容成功，将数据存放在缓存区 if self.queue_image.full(): # 队列满，队头出队 self.queue_image.get() # 队尾添加数据 self.queue_image.put(img) else: # 队尾添加数据 self.queue_image.put(img) # 直接读取图片 def read(self): \u0026#34;\u0026#34;\u0026#34; 直接读取从rtsp流中获取到的图片，不进行额外加工 可能为空，需做判空处理 \u0026#34;\u0026#34;\u0026#34; return self.queue_image.get() # 读取视频帧 def get_frame(self): \u0026#34;\u0026#34;\u0026#34; 获取加工后的图片，可以直接返回给前端显示 \u0026#34;\u0026#34;\u0026#34; img = self.queue_image.get() if img is None: return None else: # 压缩图片，否则图片过大，编码效率慢，视频延迟过高 img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25) # 对图片进行编码 ret, jpeg = cv2.imencode(\u0026#39;.jpeg\u0026#39;, img) return jpeg.tobytes() class CameraFactory: \u0026#34;\u0026#34;\u0026#34; 相机工厂 \u0026#34;\u0026#34;\u0026#34; # 存储实例化的所有相机 cameras = {} @classmethod def get_camera(cls, camera_id: int): # 通过相机id获取相机 camera = cls.cameras.get(camera_id) if camera is None: # 查看是否存在相机，存在访问 try: camera_model = Camera.objects.get(id=camera_id) base_camera = BaseCamera(camera_model=camera_model) if base_camera is not None: cls.cameras.setdefault(camera_id, base_camera) return cls.cameras.get(camera_id) else: return None except Camera.DoesNotExist: # 相机不存在 return None except CameraException: # 相机实例失败 return None else: # 存在相机，直接返回 return camera Django views.py：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from django.http import StreamingHttpResponse from apps.device.Camera import CameraFactory, BaseCamera def gen_display(camera: BaseCamera): \u0026#34;\u0026#34;\u0026#34; 视频流生成器功能。 \u0026#34;\u0026#34;\u0026#34; while True: # 读取图片 frame = camera.get_frame() if frame is not None: yield (b\u0026#39;--frame\\r\\n\u0026#39; b\u0026#39;Content-Type: image/jpeg\\r\\n\\r\\n\u0026#39; + frame + b\u0026#39;\\r\\n\u0026#39;) def video(request): \u0026#34;\u0026#34;\u0026#34; 视频流路由。将其放入img标记的src属性中。 例如：\u0026lt;img src=\u0026#39;https://ip:port/uri\u0026#39; \u0026gt; \u0026#34;\u0026#34;\u0026#34; # 视频流相机对象 camera_id = request.GET.get(\u0026#39;camera_id\u0026#39;) camera: BaseCamera = CameraFactory.get_camera(camera_id) # 使用流传输传输视频流 return StreamingHttpResponse(gen_display(camera), content_type=\u0026#39;multipart/x-mixed-replace; boundary=frame\u0026#39;) ","date":"2022-05-16T00:00:00Z","permalink":"/post/opencv/%E5%9F%BA%E4%BA%8Eopencv-django%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E6%B5%81%E4%BC%A0%E8%BE%93%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/","title":"基于OpenCv+Django的网络实时视频流传输（前后端分离）"},{"content":"问题： 在使用cv2.imread()读取含有中文路径的图片时，无法正常读取图片，读取到的内容为None。\n原因： opencv在使用cv2.imread()读取图片时，只能接收ASCII码的路径参数，导致cv2在读取含有中文路径的图片时为None，无法正常读取图片。\n解决方法： 使用np.fromfile()读取路径为np.uint8\t格式，然后使用cv2.imdecode()读取数据，并将数据转换为图片格式。\ncv2.imdecode()： 从指定的内存缓存中读取数据，并把数据转换(解码)成图像格式。\n示例：\n1 2 3 4 5 6 7 8 import cv2 import numpy as np if __name__ == \u0026#39;__main__\u0026#39;: img = cv2.imdecode(np.fromfile(r\u0026#39;C:\\Users\\focus\\Pictures\\背景图片\\希望之鲸.jpg\u0026#39;, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.namedWindow(\u0026#39;img\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;img\u0026#39;, img) cv2.waitKey(0) ","date":"2022-03-06T00:00:00Z","permalink":"/post/opencv/opencv%E8%AF%BB%E5%8F%96%E4%B8%AD%E6%96%87%E8%B7%AF%E5%BE%84/","title":"OpenCv读取中文路径"}]