[{"content":"Hugo博客教程（一） 博客 静态博客 静态博客是指利用生成工具（如：Hugo、Hexo）等将博文编译成静态文件的一种博客系统。博主只需要将生成文件部署在静态服务器上即可被互联网访问，在访问时，直接获取静态资源，不需要向数据库中请求博文、图片等信息。\n静态博客的优缺点 优点\n速度快：用户在访问博客时，只需要获取静态资源，不需要向服务器查询博文、图片等信息。\n部署方便、成本低：市面上有许多免费开源的托管程序，不需要承担高昂的服务器费用。\n维护方便：服务器维护成本低。\n迁移方便：无数据库系统，迁移时，不需要专门进行数据库迁移操作，只需保存原始博文即可。\n安全：无需担心数据库注入、跨站攻击等网络安全问题。\n缺点\n不支持原生注册登录、原生评论，需要使用第三方评论工具。第三方评论工具的安全性和速度质疑。\n入门难度大，不易上手。静态博客的内容管理和操作都有一定的难度，需要一定的编程基础。\n常见的静态博客 Hexo 基于Node.js的静态网站生成器，近几年（截止到2023年）的发展不如以前那么好，主题多，教程多，官方文档丰富，可以很快的搭建出漂亮的博客页面。由于其基于Node.js的特点，当博客数量增多时，渲染时间长。\n所以Hexo适用于博客数量少，更新周期长的博主。\nHugo Hugo是一个基于Go语言开发的静态网站生成器，Hugo的突出特点是简洁、灵活、高效。近几年（截止到2023年）发展迅速，越来越多的网站开始使用Hugo搭建。相比于Hexo，其渲染速度快，配置简单。但是其主题相比于Hexo较少。\nHugo适合于博客数量多，更新周期短的博主。\n动态博客 动态博客是指当服务器收到访问请求时，会结合数据库，调用相应的程序，动态生成需要传回的页面文件。动态博客相比于静态博客最大的区别在于其需要数据库的参与。\n动态博客的优缺点 优点\n网页动态生成，对于不同用户，不同时间的访问展现不同的页面内容。\n功能强大：动态博客相比于静态博客的功能更加强大。比如对数据库的支持、注册登录、访问量统计、原生评论的支持。\n交互性强：因为其支持原生评论和访问量统计的特点，相比于静态博客具有更好的交互性。\n缺点\n浪费系统资源：因为其与数据库交互的，所以相比于静态博客更消耗系统资源，浏览速度慢。\n易遭受攻击：因为动态博客需要支持数据库，还有后端代码，所以更易受到数据库注入和跨站攻击等威胁。\n维护迁移困难：相比于静态博客只需要保存静态资源，动态博客的迁移不仅需要重新部署博客，还需要迁移数据库，修改配置等操作，在迁移中容易出现操作失误导致迁移失败重新迁移。\n成本高：需要独立的服务器部署博客网站。\n常见的动态博客 WordPress 全球最著名的博客网站，并逐步演化为内容管理系统软件。拥有世界上最强大的插件和模板。功能强大、扩展性强。缺点是插件和模板对于国内的支持不好，国内访问速度缓慢。\nTypecho 国内开源的一个动态博客平台，相比于WordPress更加轻巧、快速。原生默认采用MarkDown编辑器，相比于WordPress的编辑器更加高效。\n为什么选择静态博客 静态博客和动态博客相比各有优劣，但是相比较而言，搭建个人博客，最方便、成本最低、体验最好的就是静态博客。相比于动态博客需要的服务器部署，目前有很多平台支持免费的静态博客部署，成本更低，有需要的只需要买一个域名即可支持每年搭建个人博客所需要的金钱耗费。随着个人博客的发展，静态博客也是目前的趋势所在。\n当然动态博客也有自己的优势，动态博客的功能性、互操性更强，而且动态博客需要部署在服务器上，有自己的一台服务器可以干很多事情，不仅是搭建个人博客，甚至可以搭建自己的云盘、图库、邮件系统、甚至是通过服务器来学习相关的Linux操作系统知识。\n在众多静态博客中，Hugo不是最流行的，但却是未来的静态博客的趋势所在。相比于Hexo的需要安装Node.js，Hugo基于Go打包的二进制文件，只需要把文件下载下来并添加到环境变量中即可使用，且Hugo的渲染速度相比于Hexo更快，更适合有长期写博客人的需求。\nHugo的安装与配置 Hugo中文文档 (gohugo.org)\nHugo官方官网(gohugo.io)\nHugo安装包下载地址：Releases · gohugoio/hugo (github.com)\n在下载Hugo安装包时，有Hugo和Hugo-extended两种可运行文件下载，其中Hugo仅支持JS，Hugo-extended是Hugo的扩展版本，在支持JS的基础上还支持TS，所以在下载时建议下载Hugo-extended版本的可执行文件。\nWindows系统的安装与配置 在Hugo安装包下载地址：Releases · gohugoio/hugo (github.com)下载好Hugo.exe文件后，将Hugo.exe文件放在想要存放的位置即可，比如我这里放在D:\\Blog\\Hugo文件夹下面，此时在该文件夹下面打开cmd命令提示符即可运行Hugo的相关命令，运行命令Hugo命令实际上就是在调用Hugo.exe文件。\nWindows环境变量配置 此电脑 \u0026ndash; 属性 \u0026ndash; 高级系统设置 \u0026ndash; 高级 \u0026ndash;环境变量 \u0026ndash; Path\n在Windows的系统环境变量配置中，添加存放Hugo.exe文件的文件夹，确定之后即可在其他任意地方运行Hugo命令而不是仅在安装位置运行。\nLinux系统的安装与配置 Hugo在Linux上的安装与配置和Windows类似。首先wget下载指定的Hugo压缩文件（tar.gz文件一般是Linux系统的压缩文件），以v0.110.0版本为例：\n1 2 3 4 # 下载指定版本的Hugo文件 wget https://github.com/gohugoio/hugo/releases/download/v0.110.0/hugo_extended_0.110.0_linux-amd64.tar.gz # 解压tar.gz压缩文件 tar -zxvf hugo_extended_0.110.0_linux-amd64.tar.gz 解压后，使用mv命令将可执行文件移动到想要存放的路径。\nLinux环境变量配置 Linux修改本用户的环境变量一般需要修改用户目录下的bashrc文件即~/.bashrc文件，在文件中加入export PATH=$PATH:{PATH}即可，修改后的文件不会立即生效，需要使用source ~/.bashrc命令重新加载bashrc文件即可完成环境变量配置。\n1 2 3 4 5 6 7 8 # 打开~/.bashrc文件 vim ~/.bashrc # 在bashrc文件中加入环境变量配置 # 在修改bashrc文件时注意添加注释，避免之后找不到相关配置 # /home/user/blog/Hugo是我存放Hugo文件的目录，在配置时根据自己的情况按需修改 export PATH=$PATH:/home/user/blog/Hugo # 保存修改，退出后在shell界面重新加载bashrc文件 source ~/.bashrc 安装检查 在配置好环境变量后，在cmd或者shell（尽量不要在可执行文件存放的位置中）中运行Hugo命令检查是否安装成功，一般而言使用version查看是否安装成功。\n在cmd和shell中执行：\n1 hugo version 成功示例：\n1 hugo v0.110.0-e32a493b7826d02763c3b79623952e625402b168+extended windows/amd64 BuildDate=2023-01-17T12:16:09Z VendorInfo=gohugoio ","date":"2023-02-01T00:00:00Z","permalink":"/post/blog/hugo/hugo%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%E4%B8%80/","title":"Hugo博客教程（一）"},{"content":"使用VideoCapture读取视频流 在使用OpenCv处理视频时，无论是视频文件还是摄像头画面，都要使用VideoCapture类来进行每一帧图像的处理。当我们使用视频文件作为参数时，OpenCv则打开视频文件，进行每一帧画面的读取。当我们传递摄像机编号时，OpenCv则打开相机，实时读取相机画面。\n获取VideoCaptrue实例：\n1 2 3 4 # 读取视频文件 cv2.VideoCapture(\u0026#39;video.mp4\u0026#39;) # 打开摄像机 cv2.VideoCapture(0) 使用VideoCapture读取海康RTSP流 RTSP流 在使用OpenCv进行计算机视觉处理时，我们很多时候需要连接外部相机，如海康威视。监控相机的常见视频传输协议有：RTSP、RTMP（以RTSP为主） RTSP与RTMP比较：\nRTSP：低时延，实现难度大，适合视频聊天和视频监控 RTMP：低时延，实现难度大，适合视频聊天和视频监控 目前市面上的相机大多以RTSP流协议为主。 在读取海康相机时，需要使用VideoCapture读取RTSP流协议的内容，而不是通过相机编号直接读取。\n1 2 3 4 5 6 7 8 9 10 \u0026#34;\u0026#34;\u0026#34; 海康相机rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 \u0026#34;\u0026#34;\u0026#34; 使用VideoCapture读取RTSP流示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 使用rtsp流打开相机 def open_camera(username: str, password: str, ip: str, port: int): \u0026#34;\u0026#34;\u0026#34; 使用rtsp流打开相机 rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 :return:相机是否打开，相机 \u0026#34;\u0026#34;\u0026#34; try: # 使用rtsp流打开相机 cam = cv2.VideoCapture(f\u0026#39;rtsp://{username}:{password}@{ip}:{port}/h264/ch1/main/av_stream\u0026#39;) return True, cam except cv2.error: # 捕获cv异常 # 打开相机失败 return False, None ping3 在使用RTSP流读取相机内容时，若IP错误，或相机连接异常，则VideoCapture无法访问相机，VideoCapture实例访问超时且程序异常，在使用PyQt等GUI程序中，程序可能出现异常闪退情况，所以在连接RTSP流前，请先对相机IP进行预校验，减少出错概率。可以在访问相机之前，通过ping 相机IP的方式来对IP进行预校验。 在Python中可以使用ping3库对IP进行ping测试。\nping3.ping成功默认返回秒为单位 ping3.ping参数错误返回False ping3.ping失败时返回None ping3.ping函数返回说明：\nReturns: The delay in seconds/milliseconds, False on error and None on timeout.\nping3.ping示例：\n1 2 3 4 5 6 import ping3 if __name__ == \u0026#39;__main__\u0026#39;: print(ping3.ping(\u0026#39;focus-wind.com\u0026#39;)) print(ping3.ping(\u0026#39;https://focus-wind.com\u0026#39;)) print(ping3.ping(\u0026#39;192.168.1.64\u0026#39;)) ping3.ping运行结果：\n1 2 3 4 5 6 # ping focus-wind.com ping成功 0.03125762939453125 # ping https://focus-wind.com 参数异常 False # ping 192.168.1.64 无法访问对应IP None 完整访问RTSP流示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def open_camera(username: str, password: str, ip: str, port: int = 554): \u0026#34;\u0026#34;\u0026#34; 使用rtsp流打开相机 rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 :return:相机是否打开，相机 \u0026#34;\u0026#34;\u0026#34; try: # ping IP，IP预检验 if ping3.ping(ip) is None or not ping3.ping(ip): # ping的结果为None或False，ping失败，不存在该IP return False, None else: # 使用rtsp流打开相机 cam = cv2.VideoCapture(f\u0026#39;rtsp://{username}:{password}@{ip}:{port}/h264/ch1/main/av_stream\u0026#39;) return True, cam except cv2.error: # 捕获cv异常 # 打开相机失败 return False, None 获取视频流信息 一般视频流的信息主要包含画面的宽高以及视频显示帧率，对于视频文件，还包括总共有多少帧画面。针对这些信息，我们可以使用VideoCapture类的get方法获取相关信息。\n1 2 3 4 5 6 7 8 # 获取视频帧的宽 width = cam.get(cv2.CAP_PROP_FRAME_WIDTH) # 获取视频帧的高 height = cam.get(cv2.CAP_PROP_FRAME_HEIGHT) # 获取视频帧的帧率 fps = cam.get(cv2.CAP_PROP_FPS) # 获取视频文件的总帧数 frame_count = cam.get(cv2.CAP_PROP_FRAME_COUNT) 针对获取总帧数函数，若相机不支持获取总帧数，则返回0，获取总帧数仅对视频文件有意义。\n获取帧画面 直接调用VideoCapture类的read方法，read方法会返回两个参数，一个为是否成功标志，一个为帧画面。 read方法返回参数：\n成功，BGR格式的numpy.ndarray三维数组 失败，None read使用示例：\n1 2 # 获取帧画面 ret, frame = cam.read() 在调用read方法时，有时候可能会访问失败，所以为避免访问失败，可以采用while循环确保读取顺利。\n1 2 3 4 5 # 获取帧画面 ret, frame = cam.read() # 循环读取，确保读取成功 while not ret: ret, frame = cam.read() 读取帧画面优化 OpenCv底层基于ffmpeg读取视频，在OpenCv读取视频流时，会设置缓存区，将视频流读取到缓存区中，但是使用缓存区的话，会导致页面堆积，页面延迟高过，所以为了避免OpenCv缓存区视频流堆积的情况，可以使用线程实时读取OpenCv画面，将读取的每一帧内容存在队列中，在需要获取帧画面时，获取队列中的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 import queue import threading import cv2 class CameraThread(threading.Thread): # 保存实例化相机，通过实例化相机操作相机 camera = None # 保存每一帧从rtsp流中读取到的画面 queue_image = queue.Queue(maxsize=10) # 线程体是否循环执行标志 flag_run = False # 相机线程调用函数 def run(self) -\u0026gt; None: while self.flag_run: try: # 捕获异常，避免读取视频操作因异常而退出 # 相机实例存在，判断相机是否打开 if self.camera.is_opened(): # 相机已打开，读取相机内容 ret, frame = self.camera.read() if not ret or frame is None: # 读取相机内容失败 break if ret: # 将内容添加到队列中 # 判断队列是否满 if self.queue_image.full(): # 队列满，队头出队 self.queue_image.get() # 队尾添加数据 self.queue_image.put(frame) else: # 队尾添加数据 self.queue_image.put(frame) except cv2.error as error: # 捕获cv异常 # 因为子线程会一直调用该程序，可对捕获到的异常不进行处理 print(error) pass except Exception as error: # 捕获Exception异常 print(error) pass # setter：设置相机的camera对象 def set_camera(self, camera): \u0026#34;\u0026#34;\u0026#34; 设置相机的camera对象 \u0026#34;\u0026#34;\u0026#34; # 设置相机的camera self.camera = camera # 获取队列中的RGB图像 def get_image(self): \u0026#34;\u0026#34;\u0026#34; 获取队列中的RGB图像 :return: img: RGB图像 \u0026#34;\u0026#34;\u0026#34; # 读取队列中的图片 img = self.queue_image.get() # img为None，读取失败，队列还未获取到图片 while img is None: # 一直读取图片，直到读取图片成功 img = self.queue_image.get() # 返回读取到的内容 return img # 停止运行 def run_stop(self): self.flag_run = False # 开始运行 def run_start(self): self.flag_run = True ","date":"2022-06-03T00:00:00Z","permalink":"/post/opencv/%E5%9F%BA%E4%BA%8Eopencv%E7%9A%84%E8%A7%86%E9%A2%91%E6%B5%81%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/","title":"基于OpenCv的视频流处理方法"},{"content":"问题： 在使用cv2.imshow()显示图片时，只能显示图片的部分内容，无法完全显示图片内容。\n原因： 查看cv2.imshow()函数说明可知，opencv在使用cv2.imshow()显示图片时，是在指定窗口中显示图片，若在调用cv2.imshow()函数之前，没有调用创建窗口的函数，则默认使用cv2.WINDOW_AUTOSIZE标记创建默认窗口，如果需要显示大于屏幕分辨率的图像，则需要在使用cv2.imshow()之前调用cv2.namedWindow(\u0026quot;\u0026quot;, cv2.WINDOW_NORMAL)\nIf the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE. 如果该窗口不是在此函数之前创建的，则假定使用cv:：WINDOW_AUTOSIZE创建窗口。\nIf you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\u0026quot;\u0026quot;, WINDOW_NORMAL) before the imshow. 如果需要显示大于屏幕分辨率的图像，则需要在imshow之前调用namedWindow(\u0026quot;\u0026quot;, WINDOW_NORMAL)。\n解决方法： 在使用cv2.imshow()之前，调用cv2.namedWindow()函数，设置显示窗口属性。若调用cv2.namedWindow()函数图片仍显示不全，可调用cv2.resize()函数使图片的分辨率在显示屏的分辨率也可使图片完全显示。\n示例： 直接调用imshow()显示图片：\n1 2 3 4 5 6 7 import cv2 import numpy as np if __name__ == \u0026#39;__main__\u0026#39;: img = cv2.imdecode(np.fromfile(r\u0026#39;C:\\Users\\focus\\Pictures\\背景图片\\希望之鲸.jpg\u0026#39;, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.imshow(\u0026#39;img\u0026#39;, img) cv2.waitKey(0) 设置namedWindow()：\n1 2 3 4 5 6 7 8 import cv2 import numpy as np if __name__ == \u0026#39;__main__\u0026#39;: img = cv2.imdecode(np.fromfile(r\u0026#39;C:\\Users\\focus\\Pictures\\背景图片\\希望之鲸.jpg\u0026#39;, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.namedWindow(\u0026#39;img\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;img\u0026#39;, img) cv2.waitKey(0) ","date":"2022-05-16T00:00:00Z","permalink":"/post/opencv/opencv-cv2.imshow%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%E4%B8%8D%E5%85%A8/","title":"OpenCv-cv2.imshow()显示图片不全"},{"content":"使用OpenCv捕获摄像机画面后，我们有时候需要将画面显示在界面上。本博客基于Django的前后端分离模式，将视频流从后端读取，传送给前端显示。\nDjango流传输实例：StreamingHttpResponse 在使用Django进行视频流传输时，无法使用HttpResponse，JsonResponse等对象对内容直接传输，需要使用StreamingHttpResponse流式传输一个响应给浏览器。StreamingHttpResponse不是HttpResponse的子类，因此他们之间的API略有不同。StreamingHttpResponse与HttpResponse之间有以下显著区别：\n应该给StreamingHttpResponse一个迭代器，产生字节字符串作为内容。 不应该直接访问StreamingHttpResponse的内容，除非通过迭代器响应对象本身。 StreamingHttpResponse没有content属性。相反，他有一个streaming_content属性。 无法使用类文件对象的tell()何write()方法。这样会引起一个异常。 Django传输视频流 因为使用Django的StreamingHttpResponse类进行流传输，所以我们首先需要生成一个视频流的迭代器，在迭代器中，需要将从opencv中获取到的numpy.ndarray三维数组转换为字节类型的，然后传输到前端。\n传输视频流：\n读取图片 图片压缩（针对分辨率较高的界面） 对图片进行解码 转换为byte类型 传输视频流 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import cv2 from django.http import StreamingHttpResponse def gen_display(camera): \u0026#34;\u0026#34;\u0026#34; 视频流生成器功能。 \u0026#34;\u0026#34;\u0026#34; while True: # 读取图片 ret, frame = camera.read() if ret: # 将图片进行解码 ret, frame = cv2.imencode(\u0026#39;.jpeg\u0026#39;, frame) if ret: # 转换为byte类型的，存储在迭代器中 yield (b\u0026#39;--frame\\r\\n\u0026#39; b\u0026#39;Content-Type: image/jpeg\\r\\n\\r\\n\u0026#39; + frame.tobytes() + b\u0026#39;\\r\\n\u0026#39;) def video(request): \u0026#34;\u0026#34;\u0026#34; 视频流路由。将其放入img标记的src属性中。 例如：\u0026lt;img src=\u0026#39;https://ip:port/uri\u0026#39; \u0026gt; \u0026#34;\u0026#34;\u0026#34; # 视频流相机对象 camera = cv2.VideoCapture(0) # 使用流传输传输视频流 return StreamingHttpResponse(gen_display(camera), content_type=\u0026#39;multipart/x-mixed-replace; boundary=frame\u0026#39;) 在使用海康威视等分辨率较高的相机时，直接解码，延迟过高，所以需要先对图片进行压缩，然后解码。\n经测试，海康相机使用0.25的压缩倍率显示压缩效率较好，当大于0.25时，延迟较高，小于0.25时，界面显示较差\n迭代器优化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def gen_display(camera): \u0026#34;\u0026#34;\u0026#34; 视频流生成器功能。 \u0026#34;\u0026#34;\u0026#34; while True: # 读取图片 ret, frame = camera.read() if ret: frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25) # 将图片进行解码 ret, frame = cv2.imencode(\u0026#39;.jpeg\u0026#39;, frame) if ret: # 转换为byte类型的，存储在迭代器中 yield (b\u0026#39;--frame\\r\\n\u0026#39; b\u0026#39;Content-Type: image/jpeg\\r\\n\\r\\n\u0026#39; + frame.tobytes() + b\u0026#39;\\r\\n\u0026#39;) 前端显示视频流 在Django中配置路由后，在浏览器端直接访问视频url即可看到视频显示画面。 在前端HTML5中，将视频路由写入img标签的src属性中，即可访问视频流界面。例如：\u0026lt;img src=\u0026lsquo;https://ip:port/uri\u0026rsquo; 前端显示视频流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;基于OpenCv+Django的网络实时视频流传输（前后端分离）\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- 显示视频流 --\u0026gt; \u0026lt;img src=\u0026#34;http://127.0.0.1:8000/api/cv/display\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 显示结果：\n在前端显示视频流中，可以通过调整img标签的属性来调整界面显示位置，显示大小。所以在进行视频流前后端传输中，在保证视频显示清晰度的情况下，建议使用前端来调整界面大小。\n调整界面前端显示视频样式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;基于OpenCv+Django的网络实时视频流传输（前后端分离）\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; #video { width: 500px; height: 500px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- 显示视频流 --\u0026gt; \u0026lt;div align=\u0026#34;center\u0026#34;\u0026gt;\u0026lt;img src=\u0026#34;http://127.0.0.1:8000/api/cv/display\u0026#34; id=\u0026#34;video\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 显示结果：\n视频流传输优化 在项目中，我们可能经常需要对多个相机进行处理，而不是对一个相机进行操作，所以我们可以使用相机工厂来获取相机。在实例化相机后，需要开启一个线程，及时更新缓存队列，确保OpenCv不会因为缓存过多而造成缓存区堵塞，界面延迟。\n使用线程实时读取OpenCv的内容到队列中 使用相机工厂来获取相机 在示例代码中，camera_model为自定义model，其中代码需要用到的数据有数据表记录的唯一标识id，相机的访问api：camera_api\n相机类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import queue import threading import cv2 from apps.device.models import Camera class CameraException(Exception): message = None # 初始化异常 def __init__(self, message: str): # 初始化异常，定位异常信息描述 self.message = message def __str__(self): return self.message class BaseCamera: # 相机操作对象 cam = None # 保存每一帧从rtsp流中读取到的画面，使用opencv读取，为BGR图片 queue_image = queue.Queue(maxsize=10) # 后台取帧线程 thread = None # 相机Model camera_model = None # 相机基类 def __init__(self, camera_model: Camera): \u0026#34;\u0026#34;\u0026#34; 使用rtsp流初始化相机参数 rtsp格式：rtsp://[username]:[password]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream username: 用户名。例如admin。 password: 密码。例如12345。 ip: 为设备IP。例如 192.0.0.64。 port: 端口号默认为554，若为默认可不填写。 codec：有h264、MPEG-4、mpeg4这几种。 channel: 通道号，起始为1。例如通道1，则为ch1。 subtype: 码流类型，主码流为main，辅码流为sub。 \u0026#34;\u0026#34;\u0026#34; self.cam = cv2.VideoCapture(camera_model.camera_api) if self.cam.isOpened(): # 相机打开成功,启动线程读取数据 self.thread = threading.Thread(target=self._thread, daemon=True) self.thread.start() else: # 打开失败，相机流错误 raise CameraException(\u0026#34;视频流接口访问失败\u0026#34;) def _thread(self): \u0026#34;\u0026#34;\u0026#34; 相机后台进程，持续读取相机 opencv读取时会将信息存储到缓存区里，处理速度小于缓存区速度，会导致资源积累 \u0026#34;\u0026#34;\u0026#34; # 线程一直读取视频流，将最新的视频流存在队列中 while self.cam.isOpened(): ret, img = self.cam.read() if not ret or img is None: # 读取相机失败 pass else: # 读取内容成功，将数据存放在缓存区 if self.queue_image.full(): # 队列满，队头出队 self.queue_image.get() # 队尾添加数据 self.queue_image.put(img) else: # 队尾添加数据 self.queue_image.put(img) # 直接读取图片 def read(self): \u0026#34;\u0026#34;\u0026#34; 直接读取从rtsp流中获取到的图片，不进行额外加工 可能为空，需做判空处理 \u0026#34;\u0026#34;\u0026#34; return self.queue_image.get() # 读取视频帧 def get_frame(self): \u0026#34;\u0026#34;\u0026#34; 获取加工后的图片，可以直接返回给前端显示 \u0026#34;\u0026#34;\u0026#34; img = self.queue_image.get() if img is None: return None else: # 压缩图片，否则图片过大，编码效率慢，视频延迟过高 img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25) # 对图片进行编码 ret, jpeg = cv2.imencode(\u0026#39;.jpeg\u0026#39;, img) return jpeg.tobytes() class CameraFactory: \u0026#34;\u0026#34;\u0026#34; 相机工厂 \u0026#34;\u0026#34;\u0026#34; # 存储实例化的所有相机 cameras = {} @classmethod def get_camera(cls, camera_id: int): # 通过相机id获取相机 camera = cls.cameras.get(camera_id) if camera is None: # 查看是否存在相机，存在访问 try: camera_model = Camera.objects.get(id=camera_id) base_camera = BaseCamera(camera_model=camera_model) if base_camera is not None: cls.cameras.setdefault(camera_id, base_camera) return cls.cameras.get(camera_id) else: return None except Camera.DoesNotExist: # 相机不存在 return None except CameraException: # 相机实例失败 return None else: # 存在相机，直接返回 return camera Django views.py：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 from django.http import StreamingHttpResponse from apps.device.Camera import CameraFactory, BaseCamera def gen_display(camera: BaseCamera): \u0026#34;\u0026#34;\u0026#34; 视频流生成器功能。 \u0026#34;\u0026#34;\u0026#34; while True: # 读取图片 frame = camera.get_frame() if frame is not None: yield (b\u0026#39;--frame\\r\\n\u0026#39; b\u0026#39;Content-Type: image/jpeg\\r\\n\\r\\n\u0026#39; + frame + b\u0026#39;\\r\\n\u0026#39;) def video(request): \u0026#34;\u0026#34;\u0026#34; 视频流路由。将其放入img标记的src属性中。 例如：\u0026lt;img src=\u0026#39;https://ip:port/uri\u0026#39; \u0026gt; \u0026#34;\u0026#34;\u0026#34; # 视频流相机对象 camera_id = request.GET.get(\u0026#39;camera_id\u0026#39;) camera: BaseCamera = CameraFactory.get_camera(camera_id) # 使用流传输传输视频流 return StreamingHttpResponse(gen_display(camera), content_type=\u0026#39;multipart/x-mixed-replace; boundary=frame\u0026#39;) ","date":"2022-05-16T00:00:00Z","permalink":"/post/opencv/%E5%9F%BA%E4%BA%8Eopencv-django%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E6%B5%81%E4%BC%A0%E8%BE%93%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/","title":"基于OpenCv+Django的网络实时视频流传输（前后端分离）"},{"content":"问题： 在使用cv2.imread()读取含有中文路径的图片时，无法正常读取图片，读取到的内容为None。\n原因： opencv在使用cv2.imread()读取图片时，只能接收ASCII码的路径参数，导致cv2在读取含有中文路径的图片时为None，无法正常读取图片。\n解决方法： 使用np.fromfile()读取路径为np.uint8\t格式，然后使用cv2.imdecode()读取数据，并将数据转换为图片格式。\ncv2.imdecode()： 从指定的内存缓存中读取数据，并把数据转换(解码)成图像格式。\n示例：\n1 2 3 4 5 6 7 8 import cv2 import numpy as np if __name__ == \u0026#39;__main__\u0026#39;: img = cv2.imdecode(np.fromfile(r\u0026#39;C:\\Users\\focus\\Pictures\\背景图片\\希望之鲸.jpg\u0026#39;, dtype=np.uint8), cv2.IMREAD_COLOR) cv2.namedWindow(\u0026#39;img\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;img\u0026#39;, img) cv2.waitKey(0) ","date":"2022-03-06T00:00:00Z","permalink":"/post/opencv/opencv%E8%AF%BB%E5%8F%96%E4%B8%AD%E6%96%87%E8%B7%AF%E5%BE%84/","title":"OpenCv读取中文路径"}]